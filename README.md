Te dejo un README nuevo, estructurado siguiendo las buenas pr√°cticas del tutorial: responde al **qu√©, por qu√© y c√≥mo**, tiene descripci√≥n, tabla de contenido, instalaci√≥n, uso, cr√©ditos, licencia, contribuci√≥n, etc.

C√≥pialo tal cual en `README.md` y luego ajusta detalles como tu usuario de GitHub o la imagen.

````markdown
# HoloTalk 3D ‚Äì Avatares Conversacionales para Pruebas con Usuarios

> Un avatar 3D que habla, escucha y conversa con las personas, pensado para hacer **pruebas r√°pidas con usuarios** en escritorio (y f√°cilmente portable a VR porque est√° hecho en Unity).

HoloTalk 3D es un peque√±o laboratorio de **agentes virtuales**: toma como base el proyecto [GPTAvatar](https://github.com/SethRobinson/GPTAvatar) y lo adapta para:
- funcionar en **espa√±ol**,
- simplificar la configuraci√≥n para pruebas con participantes,
- documentar claramente c√≥mo instalarlo, ejecutarlo y usarlo en estudios de experiencia de usuario.

---

## Tabla de contenidos

1. [Motivaci√≥n y descripci√≥n](#motivaci√≥n-y-descripci√≥n)
2. [Caracter√≠sticas principales](#caracter√≠sticas-principales)
3. [Tecnolog√≠as usadas](#tecnolog√≠as-usadas)
4. [Requisitos previos](#requisitos-previos)
5. [Instalaci√≥n para desarrollo](#instalaci√≥n-para-desarrollo)
6. [Configuraci√≥n de `config.txt`](#configuraci√≥n-de-configtxt)
7. [Uso del ejecutable](#uso-del-ejecutable)
8. [Capturas / imagen representativa](#capturas--imagen-representativa)
9. [Contribuir al proyecto](#contribuir-al-proyecto)
10. [Cr√©ditos](#cr√©ditos)
11. [Licencia](#licencia)
12. [Trabajo futuro](#trabajo-futuro)

---

## Motivaci√≥n y descripci√≥n

### ¬øQu√© problema intenta resolver?

En muchos cursos y proyectos de investigaci√≥n sobre **agentes virtuales y realidad mixta/virtual** se necesita:

- Un agente conversacional 3D ‚Äúcre√≠ble‚Äù.
- Que hable y escuche (voz + micr√≥fono).
- Que se pueda configurar r√°pido para distintos **escenarios de prueba con usuarios** (pedir comida, tutor de idiomas, etc.).
- Y que no requiera implementar desde cero toda la integraci√≥n con modelos de lenguaje, TTS y STT.

HoloTalk 3D nace justamente de esa necesidad: tener un **prototipo listo para usar**, f√°cil de explicar a otras personas y f√°cil de adaptar a diferentes experimentos.

### ¬øQu√© es HoloTalk 3D?

Es una aplicaci√≥n de Unity que muestra uno o varios **avatares 3D conversacionales**. Cada avatar:

- Tiene una **personalidad** definida por *prompts* en un archivo de configuraci√≥n.
- Escucha al usuario por micr√≥fono (Whisper).
- Env√≠a el texto a un modelo de OpenAI (chat completions).
- Responde por texto y (opcionalmente) por voz usando Google TTS o ElevenLabs.
- Puede mover labios y ojos si se instala el plugin **SALSA LipSync Suite** (opcional, no obligatorio).

---

## Caracter√≠sticas principales

- üë§ **Avatares 3D configurables**  
  - Distintos personajes (por ejemplo, ‚ÄúProfesora de japon√©s‚Äù, ‚ÄúCajero de comida r√°pida‚Äù, etc.).
  - Cada uno con su propio prompt en espa√±ol.

- üó£Ô∏è **Interacci√≥n por voz**  
  - El usuario habla por micr√≥fono.
  - OpenAI Whisper transcribe lo que dijo.
  - El agente responde.

- üîä **S√≠ntesis de voz (opcional pero recomendada)**  
  - Google Cloud Text-to-Speech (espa√±ol y otros idiomas).
  - ElevenLabs para voces m√°s expresivas (si se quiere).

- üí¨ **Soporte completo en espa√±ol**  
  - Prompts en espa√±ol.
  - Instrucciones y comentarios pensados para experimentos con usuarios hispanohablantes.

- üé≠ **Lipsync opcional con SALSA**  
  - Si instalas SALSA LipSync Suite, el avatar mover√° la boca y ojos de forma autom√°tica.
  - Si no lo instalas, el proyecto **igualmente funciona** (el avatar habla por audio pero sin animaci√≥n de labios).

- üß™ **Pensado para pruebas con usuarios**  
  - Escenarios simples (por ejemplo: ‚Äúpide un combo y conf√≠rmalo‚Äù).
  - F√°cil de explicar en una sesi√≥n de laboratorio o en clase.

---

## Tecnolog√≠as usadas

- **Unity 2022.2+**
- **C#** para scripts.
- **OpenAI API**  
  - Modelos de chat (por ejemplo: `gpt-3.5-turbo`, `gpt-4o-mini`, `gpt-4.1-mini` seg√∫n tu cuenta).
  - Whisper (speech-to-text).
- **Google Cloud Text-to-Speech** (opcional, recomendado para voz en espa√±ol).
- **ElevenLabs Text-to-Speech** (opcional).
- **SALSA LipSync Suite v2** (opcional, para lipsync y animaciones faciales).

---

## Requisitos previos

### Software

- **Windows 10/11**
- **Unity Hub** instalado.
- **Unity Editor 2022.2.x o superior** (idealmente la misma rama que el proyecto original GPTAvatar).
- Un editor de texto (VS Code, Notepad++, etc.) para editar `config.txt`.

### Cuentas y API keys

1. **OpenAI**
   - Crear cuenta en <https://platform.openai.com>
   - Generar una API key en **API keys**.
   - Esa misma clave se usa tanto para:
     - Whisper (voz ‚Üí texto).
     - Chat completions (texto ‚Üí respuesta).

2. **Google Cloud (opcional, recomendado)**
   - Crear proyecto en <https://console.cloud.google.com>
   - Habilitar **Text-to-Speech API**.
   - Crear una API key de tipo ‚ÄúAPI key‚Äù en *APIs & Services ‚Üí Credentials*.

3. **ElevenLabs (opcional)**
   - Crear cuenta en <https://elevenlabs.io>
   - Generar una API key en el panel de usuario.

### SALSA LipSync Suite (opcional)

- **No es necesaria** para que el proyecto funcione.
- Solo se necesita si quieres:
  - Animaci√≥n de labios sincronizada con la voz.
  - Movimiento de ojos/parpadeo m√°s avanzado.

Si no tienes SALSA:
- Deja comentada la integraci√≥n en `AIManager.cs` (o usa la versi√≥n del script sin SALSA).
- El agente seguir√° escuchando y hablando por audio.

---

## Instalaci√≥n para desarrollo

### 1. Clonar el repositorio

```bash
git clone https://github.com/TU-USUARIO/holotalk-3d.git
cd holotalk-3d
````

(Sustituye `TU-USUARIO` y el nombre del repo por los tuyos reales.)

### 2. Abrir el proyecto en Unity

1. Abrir **Unity Hub**.
2. Clic en **Add ‚Üí Add project from disk**.
3. Seleccionar la carpeta ra√≠z clonada (deber√≠as ver `Assets`, `ProjectSettings`, etc.).
4. Abrir con **Unity 2022.2.x o superior**.

### 3. Verificar dependencias

* Espera a que Unity importe todos los assets.
* Si ves errores de SALSA y **no tienes SALSA**, aseg√∫rate de estar usando la versi√≥n de `AIManager.cs` **sin** la l√≠nea:

  ```csharp
  #define CRAZY_MINNOW_PRESENT
  ```
* Revisa la consola de Unity; si solo hay warnings de audio o mensajes informativos, puedes ignorarlos por ahora.

### 4. Preparar `config.txt`

En la carpeta ra√≠z del proyecto:

1. Localiza `config_template.txt`.

2. Haz una copia y ren√≥mbrala a **`config.txt`**.

3. Abre `config.txt` con tu editor de texto favorito.

4. Rellena las claves m√≠nimas:

   ```txt
   set_openai_api_key|TU_API_KEY_DE_OPENAI
   set_google_api_key|TU_API_KEY_DE_GOOGLE_TTS   # opcional (puede quedarse vac√≠o)
   set_elevenlabs_api_key|TU_API_KEY_DE_ELEVENLABS  # opcional (puede quedarse vac√≠o)

   # Modelo de OpenAI
   set_openai_model|gpt-3.5-turbo
   ```

5. (Opcional) Ajusta los prompts y voces de cada ‚Äúamigo‚Äù (friend) seg√∫n tus necesidades de prueba.

### 5. Abrir la escena principal

* En la ventana **Project**, busca la escena `Main` (normalmente en la ra√≠z de `Assets`).
* Haz doble clic para abrirla.
* Pulsa **Play** para ejecutar el prototipo dentro del Editor.

---

## Configuraci√≥n de `config.txt`

El archivo `config.txt` controla:

* La API key de OpenAI, Google, ElevenLabs.
* El modelo de OpenAI a usar.
* Los distintos avatares (‚Äúfriends‚Äù):

  * Idioma.
  * Voz.
  * Prompt base.
  * Prompt de direcci√≥n (estilo de respuesta).
  * Prompt de introducci√≥n (para el bot√≥n de ‚ÄúAdvice‚Äù / ‚ÄúStart‚Äù).

Ejemplo (resumido) de un ‚Äúfriend‚Äù pensado para espa√±ol:

```txt
add_friend|Profesora de japon√©s
set_friend_language|spanish
set_friend_token_memory|800
set_friend_max_tokens_to_generate|200
set_friend_temperature|0.9
set_friend_google_voice|es-ES-Neural2-C
set_friend_voice_pitch|0
set_friend_voice_speed|1.0
set_friend_visual|japanese_teacher

set_friend_base_prompt
Eres una profesora de japon√©s llamada Atsuko. Hablas con el estudiante siempre en espa√±ol claro,
y usas ejemplos en japon√©s con su traducci√≥n al espa√±ol. Tu objetivo es ayudarle a practicar
saludos, presentaciones y situaciones cotidianas sencillas.
No uses HTML ni formato raro, solo texto plano.
<END_TEXT>

set_friend_direction_prompt
Responde con menos de 60 palabras. Siempre incluye alguna frase corta en japon√©s con su traducci√≥n.
<END_TEXT>

set_friend_advice_prompt
El estudiante se sienta a comenzar su clase de japon√©s.
Pres√©ntate brevemente en espa√±ol, explica que vas a usar ejemplos en japon√©s, pero siempre traducidos,
y preg√∫ntale qu√© aspecto del japon√©s le gustar√≠a trabajar hoy (saludos, pedir comida, presentarse, etc.).
<END_TEXT>
```

Puedes a√±adir tantos ‚Äúfriends‚Äù como necesites para tus experimentos.

---

## Uso del ejecutable

### 1. Generar el ejecutable (build)

En Unity:

1. Ve a **File ‚Üí Build Settings‚Ä¶**
2. Plataforma: **PC, Mac & Linux Standalone**.
3. Target: **Windows**.
4. A√±ade la escena `Main` a la lista de escenas del build (bot√≥n **Add Open Scenes**).
5. Clic en **Build** y elige una carpeta de salida (por ejemplo `Build/`).

Esto generar√° algo como:

* `HoloTalk3D.exe`
* `HoloTalk3D_Data/`
* (Copias de otros archivos necesarios)

Aseg√∫rate de copiar tambi√©n tu `config.txt` a la **misma carpeta donde est√° el `.exe`**.

### 2. Configurar `config.txt` junto al ejecutable

En la carpeta del ejecutable:

* Debe existir un archivo `config.txt` con tus claves y configuraci√≥n.
* Si no est√°, copia el `config.txt` desde el proyecto de Unity.

### 3. Ejecutar

1. Haz doble clic en `HoloTalk3D.exe`.
2. Debe abrirse una ventana con:

   * Un avatar 3D.
   * Botones de elecci√≥n de personaje (seg√∫n tu UI).
   * Bot√≥n de micr√≥fono, bot√≥n de ‚ÄúAdvice/Start‚Äù, etc.

### 4. Flujo t√≠pico de uso en pruebas con usuarios

1. Escoger el avatar / escenario (por ejemplo, ‚ÄúBurger Barn‚Äù).
2. Pulsar el bot√≥n de **Advice/Start** para que el agente se presente.
3. Pulsar el bot√≥n del **micr√≥fono**:

   * Hablar una frase corta (3‚Äì5 segundos).
   * Esperar a que el sistema:

     * Transcriba la voz (Whisper).
     * Genere respuesta (modelo de OpenAI).
     * Reproduzca la respuesta TTS (si est√° configurada).
4. Repetir la interacci√≥n seg√∫n el protocolo de la sesi√≥n (tareas, preguntas, etc.).

> ‚ö†Ô∏è Si ves errores como `HTTP 400/401/429` en la consola integrada del juego, revisa:
>
> * Que tu API key de OpenAI sea v√°lida y tenga saldo.
> * Que el modelo configurado exista en tu cuenta.
> * Que no est√©s superando l√≠mites de uso.

---

## Capturas / imagen representativa

A√±ade una imagen en tu repositorio, por ejemplo en `docs/img/holotalk_hero.png`, con:

* El avatar 3D en primer plano.
* El cuadro de di√°logo visible.
* Un entorno que sugiera ‚Äúlaboratorio de interacci√≥n‚Äù o ‚Äúescenario de restaurante / clase‚Äù.

Y referencia la imagen as√≠:

```markdown
![HoloTalk 3D ‚Äì Avatar conversacional en acci√≥n](docs/img/holotalk_hero.png)
```

---

## Contribuir al proyecto

Este proyecto naci√≥ como parte de un trabajo acad√©mico, pero se puede extender para:

* A√±adir nuevos escenarios de interacci√≥n.
* Integrar directamente con VR (XR Interaction Toolkit).
* Mejorar la interfaz para estudios m√°s complejos.

Si quieres contribuir:

1. Haz un fork del repositorio.
2. Crea una rama descriptiva:

   ```bash
   git checkout -b feature/nueva-funcionalidad
   ```
3. Realiza tus cambios y haz commits claros.
4. Abre un Pull Request describiendo:

   * Qu√© problema resuelves.
   * Qu√© cambios hiciste.
   * C√≥mo probarlos.

---

## Cr√©ditos

* **Implementaci√≥n original**:

  * [Seth A. Robinson ‚Äì GPTAvatar](https://github.com/SethRobinson/GPTAvatar)

* **Adaptaci√≥n, prompts en espa√±ol y gu√≠a para pruebas con usuarios**:

  * (Tu nombre aqu√≠) ‚Äì dise√±o de escenarios, configuraci√≥n en espa√±ol, documentaci√≥n y README.

* **Tecnolog√≠as y servicios externos**:

  * [OpenAI](https://platform.openai.com)
  * [Google Cloud Text-to-Speech](https://cloud.google.com/text-to-speech)
  * [ElevenLabs](https://elevenlabs.io)
  * [SALSA LipSync Suite](https://crazyminnowstudio.com/unity-3d/lip-sync-salsa/)

---

## Licencia

Este proyecto est√° licenciado bajo la licencia **MIT**.

Puedes usar, copiar, modificar, fusionar, publicar, distribuir, sublicenciar y/o vender copias del software, siempre que se incluya el aviso de copyright y esta nota de permiso en todas las copias o partes sustanciales del software.

Para m√°s detalles, consulta el archivo `LICENSE` incluido en este repositorio.

---

## Trabajo futuro

Algunas direcciones interesantes:

* üéß **Integraci√≥n VR nativa**

  * Sustituir la c√°mara est√°ndar por un rig XR (OpenXR + XR Interaction Toolkit).
  * Colocar el avatar frente al usuario en un entorno VR.
  * Mantener el mismo backend de IA.

* üìä **Instrumentaci√≥n para estudios**

  * Registro de tiempos de interacci√≥n.
  * Registro autom√°tico de turnos de di√°logo.
  * Exportaci√≥n de logs a CSV/JSON.

* üß† **Perfiles de agente m√°s ricos**

  * Diferentes estilos de tutor (m√°s estricto, m√°s l√∫dico).
  * Escenarios guiados para entrenamiento de habilidades espec√≠ficas.

